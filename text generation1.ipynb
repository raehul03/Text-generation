{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOp8HfrKtcR7l4XmvOp2yhx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"wBOF-UGm0WOf"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"tc_mhsiEw5cx","executionInfo":{"status":"ok","timestamp":1741135729896,"user_tz":-60,"elapsed":3540,"user":{"displayName":"rahul mitra","userId":"18382172157927570970"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","import requests"]},{"cell_type":"code","source":["url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","response = requests.get(url)\n","text = response.text\n","\n","\n","chars = sorted(list(set(text)))\n","char_to_idx = {ch: i for i, ch in enumerate(chars)}\n","idx_to_char = {i: ch for i, ch in enumerate(chars)}\n","vocab_size = len(chars)\n","\n","\n","max_length = 40  # Length of input sequences\n","step = 3  # Step size for sampling sequences\n","sequences = []\n","next_chars = []\n","\n","for i in range(0, len(text) - max_length, step):\n","    sequences.append(text[i:i + max_length])\n","    next_chars.append(text[i + max_length])\n","\n","# Vectorize the sequences\n","X = np.zeros((len(sequences), max_length, vocab_size), dtype=bool)\n","y = np.zeros((len(sequences), vocab_size), dtype=bool)\n","\n","for i, seq in enumerate(sequences):\n","    for t, char in enumerate(seq):\n","        X[i, t, char_to_idx[char]] = 1\n","    y[i, char_to_idx[next_chars[i]]] = 1"],"metadata":{"id":"RjWtO58Mxvlr","executionInfo":{"status":"ok","timestamp":1741135746870,"user_tz":-60,"elapsed":5303,"user":{"displayName":"rahul mitra","userId":"18382172157927570970"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model = models.Sequential([\n","    layers.LSTM(128, input_shape=(max_length, vocab_size)),\n","    layers.Dense(vocab_size, activation='softmax')\n","])\n","\n","# Summary of the model\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"psp293loxx_r","executionInfo":{"status":"ok","timestamp":1741135761331,"user_tz":-60,"elapsed":1573,"user":{"displayName":"rahul mitra","userId":"18382172157927570970"}},"outputId":"372e8d4f-b049-4113-de69-3d630491cd3f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m99,328\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)                  │           \u001b[38;5;34m8,385\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">99,328</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,385</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m107,713\u001b[0m (420.75 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,713</span> (420.75 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m107,713\u001b[0m (420.75 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,713</span> (420.75 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy')"],"metadata":{"id":"RQYX6UVEx3gM","executionInfo":{"status":"ok","timestamp":1741135774474,"user_tz":-60,"elapsed":13,"user":{"displayName":"rahul mitra","userId":"18382172157927570970"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["history = model.fit(X, y,\n","                    epochs=20,  # More epochs for better results (e.g., 50+)\n","                    batch_size=128,\n","                    verbose=1,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiKTQmnBx4sE","executionInfo":{"status":"ok","timestamp":1741136121246,"user_tz":-60,"elapsed":270242,"user":{"displayName":"rahul mitra","userId":"18382172157927570970"}},"outputId":"34901f9f-7fb6-472e-fcfc-c53cad989b2d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 2.7692\n","Epoch 2/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 2.0648\n","Epoch 3/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.9126\n","Epoch 4/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.8267\n","Epoch 5/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.7520\n","Epoch 6/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.7014\n","Epoch 7/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.6618\n","Epoch 8/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.6326\n","Epoch 9/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.6018\n","Epoch 10/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.5827\n","Epoch 11/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.5597\n","Epoch 12/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.5419\n","Epoch 13/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.5189\n","Epoch 14/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.5089\n","Epoch 15/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.4956\n","Epoch 16/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.4856\n","Epoch 17/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.4689\n","Epoch 18/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.4602\n","Epoch 19/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.4503\n","Epoch 20/20\n","\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 1.4461\n"]}]},{"cell_type":"code","source":["def generate_text(model, seed_text, length=200, temperature=1.0):\n","    generated = seed_text\n","    for _ in range(length):\n","        # Prepare the input\n","        x_pred = np.zeros((1, max_length, vocab_size))\n","        for t, char in enumerate(seed_text[-max_length:]):\n","            x_pred[0, t, char_to_idx[char]] = 1\n","\n","        # Predict the next character\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        preds = np.asarray(preds).astype('float64')\n","        preds = np.log(preds + 1e-10) / temperature  # Apply temperature for diversity\n","        exp_preds = np.exp(preds)\n","        preds = exp_preds / np.sum(exp_preds)\n","\n","        # Sample the next character\n","        next_idx = np.random.choice(range(vocab_size), p=preds)\n","        next_char = idx_to_char[next_idx]\n","\n","        # Append and update seed\n","        generated += next_char\n","        seed_text = seed_text[1:] + next_char\n","\n","    return generated\n","\n","# Generate some text after training\n","seed_text = \"To be or not to be\"\n","generated_text = generate_text(model, seed_text, length=100, temperature=0.6)\n","print(\"Generated Text:\\n\", generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3q8vaAwzyz3","executionInfo":{"status":"ok","timestamp":1741136353578,"user_tz":-60,"elapsed":7031,"user":{"displayName":"rahul mitra","userId":"18382172157927570970"}},"outputId":"7e822d66-a586-4f89-9e52-81369cb5edcd"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Text:\n"," To be or not to be\n","ib''loa'srt!'alslslsllalrla,.a,?lllllt!..:rdddddddl\n","s'a,sllrl,lltrrllsll;.rslsll,alrassl\n",",sll',lbss\n"]}]}]}